# Where to go next <!-- omit in toc -->

## Contents <!-- omit in toc -->

- [Neural Networks](#neural-networks)
  - [Neural Network Elements](#neural-network-elements)
  - [Tensorflow](#tensorflow)
  - [Keras](#keras)
  - [pyTorch](#pytorch)
- [References](#references)
- [Agenda](#agenda)

## Neural Networks

Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns. They interpret sensory data through a kind of machine perception, labeling or clustering raw input. The patterns they recognize are numerical, contained in vectors, into which all real-world data, be it images, sound, text or time series, must be translated.

Neural networks help us cluster and classify. You can think of them as a clustering and classification layer on top of the data you store and manage. They help to group unlabeled data according to similarities among the example inputs, and they classify data when they have a labeled dataset to train on. (Neural networks can also extract features that are fed to other algorithms for clustering and classification; so you can think of deep neural networks as components of larger machine-learning applications involving algorithms for reinforcement learning, classification and regression.)

What kind of problems does deep learning solve, and more importantly, can it solve yours? To know the answer, you need to ask questions:

- What outcomes do I care about? Those outcomes are labels that could be applied to data: for example, spam or not_spam in an email filter, good_guy or bad_guy in fraud detection, angry_customer or happy_customer in customer relationship management.
- Do I have the data to accompany those labels? That is, can I find labeled data, or can I create a labeled dataset where spam has been labeled as spam, in order to teach an algorithm the correlation between labels and inputs?

### Neural Network Elements

Deep learning is the name we use for “stacked neural networks”; that is, networks composed of several layers.

The layers are made of nodes. A node is just a place where computation happens, loosely patterned on a neuron in the human brain, which fires when it encounters sufficient stimuli. A node combines input from the data with a set of coefficients, or weights, that either amplify or dampen that input, thereby assigning significance to inputs with regard to the task the algorithm is trying to learn; e.g. which input is most helpful is classifying data without error? These input-weight products are summed and then the sum is passed through a node’s so-called activation function, to determine whether and to what extent that signal should progress further through the network to affect the ultimate outcome, say, an act of classification. If the signals passes through, the neuron has been “activated.”

Here’s a diagram of what one node might look like.

![image](https://pathmind.com/images/wiki/perceptron_node.png)

*node diagram*

A node layer is a row of those neuron-like switches that turn on or off as the input is fed through the net. Each layer’s output is simultaneously the subsequent layer’s input, starting from an initial input layer receiving your data.

![image](https://pathmind.com/images/wiki/mlp.png)

*node connenctions*

Pairing the model’s adjustable weights with input features is how we assign significance to those features with regard to how the neural network classifies and clusters input.

![image](https://s3.amazonaws.com/keras.io/img/dl_frameworks_power_scores.png)

*Deep learning framework comparison*

### Tensorflow

TensorFlow is an end-to-end open source platform for machine learning. TensorFlow is a rich system for managing all aspects of a machine learning system.

TensorFlow APIs are arranged hierarchically, with the high-level APIs built on the low-level APIs. Machine learning researchers use the low-level APIs to create and explore new machine learning algorithms.

The following figure shows the hierarchy of TensorFlow toolkits:
![image](https://developers.google.com/machine-learning/crash-course/images/TFHierarchyNew.svg)

*TensorFlow toolkit hierarchy*

### Keras

Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.

Use Keras if you need a deep learning library that:

- Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).
- Supports both convolutional networks and recurrent networks, as well as combinations of the two.
- Runs seamlessly on CPU and GPU.

Why use Keras? Keras prioritizes developer experience

- Keras is an API designed for human beings, not machines. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear and actionable feedback upon user error.
- This makes Keras easy to learn and easy to use. As a Keras user, you are more productive, allowing you to try more ideas than your competition, faster -- which in turn helps you win machine learning competitions.
- This ease of use does not come at the cost of reduced flexibility: because Keras integrates with lower-level deep learning languages (in particular TensorFlow), it enables you to implement anything you could have built in the base language. In particular, as tf.keras, the Keras API integrates seamlessly with your TensorFlow workflows.

### pyTorch

PyTorch is a library for Python programs that facilitates building deep learning projects. PyTorch emphasizes flexibility and allows deep learning models to be expressed in idiomatic Python.
In a simple sentence, think about Numpy, but with strong GPU acceleration. Better yet, PyTorch supports dynamic computation graphs that allow you to change how the network behaves on the fly, unlike static graphs that are used in frameworks such as Tensorflow.

Why PyTorch?
- Developed by Facebook
- NumPy-like arrays on GPU’s
- Dynamic computational graphs

## References

- https://pathmind.com/wiki/neural-network
- https://www.tensorflow.org/
- https://developers.google.com/machine-learning/crash-course/first-steps-with-tensorflow/toolkit
- https://keras.io/
- https://pytorch.org/
- https://towardsdatascience.com/what-is-pytorch-a84e4559f0e3

## Agenda
1. *[Presentation](./01.presentation.md)* :clock230: **14:30**
2. *[Introduction](02.introduction.md)* **14:45**
3. *[Azure Machine Learning Studio (Preview)](03.azure-machine-learning-studio-(preview).md)* :clock330: **15:30**
4. *[Demo](04.demo.md)* :clock4: **16:00**
5. *[Where to go next](05.where-to-go-next.md)* **16:20**
6. **[Q&A](06.q&a.md)** **16:25**
